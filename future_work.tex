\section{Future Work}
We see multiple future directions for this work. We could combine a value function cost model that can predict the advantage of taking an action instead of running the MCTS simulation. Another direction can include applying deep reinforcement learning methods to solve the scheduling MDP as done in similar domains in compiler optimization in~\cite{haj2020autophase,haj2020neurovectorizer,huang2019autophase, ahn2019reinforcement}. We believe that if deep reinforcement learning (with a neural network) can generalize in that case then the runtime of the algorithm can be significantly improved as the algorithm will only need to run inference rather than retrain/research from scratch as the case in MCTS or beam search.
With limited resources, more accurate cost models are necessary for scheduling,  especially with the recent trends in customized hardware and the explosion of new applications. Such cost models need to consider the target hardware parameters and program features.

Another point for improvement in our implementation is in generating the next states during the random simulation. During the MCTS simulation phase, our implementation now generates all the possible children (next possible intermediate schedules) and then randomly picks one child. In this setting, our algorithm's cost evaluation overhead is 7.5\%  while 88\% of the time is spent on enumerating children that our standard MCTSes do not use. In other words, we see the potential for 8$\times$ runtime improvement for our MCTS algorithm. Different configurations of the MCTS impact the performance differently. Some applications seem to benefit more from greedy behavior while others work better with a random one. The $C_p$ could be further tuned and our performance could be improved if we had a different $C_p$ for different programs. This is because different programs have different costs/runtimes and thus using the same $C_p$ for all programs encourages less exploration in shorter programs. Furthermore, as we go deeper into the MCTS, the $C_p$ could be reduced to encourage less exploration as the standard deviation in the costs of the children decreases. We also observed that our MCTS can overfit to the cost model if we run it for too long. 

We plan to extend the search space to include more optimizations currently pruned such as vector sizes different than the native vector size, or not enforcing the multi-core parallelism to be at the outermost loop level. We also plan to explore more hardware targets and experiment with more autotuning methods that can further improve the performance.